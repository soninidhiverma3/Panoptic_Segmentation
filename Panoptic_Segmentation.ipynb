{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_oC2ZeogHJq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as A\n",
        "from torchvision.datasets import ImageFolder\n",
        "import PIL\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksVx9mbcqgZE"
      },
      "outputs": [],
      "source": [
        "cv2.setNumThreads(0)\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "VOC_CLASSES = [\n",
        "    \"background\",\n",
        "    \"aeroplane\",\n",
        "    \"bicycle\",\n",
        "    \"bird\",\n",
        "    \"boat\",\n",
        "    \"bottle\",\n",
        "    \"bus\",\n",
        "    \"car\",\n",
        "    \"cat\",\n",
        "    \"chair\",\n",
        "    \"cow\",\n",
        "    \"diningtable\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"motorbike\",\n",
        "    \"person\",\n",
        "    \"potted plant\",\n",
        "    \"sheep\",\n",
        "    \"sofa\",\n",
        "    \"train\",\n",
        "    \"tv/monitor\",\n",
        "]\n",
        "\n",
        "\n",
        "VOC_COLORMAP = [\n",
        "    [0, 0, 0],\n",
        "    [128, 0, 0],\n",
        "    [0, 128, 0],\n",
        "    [128, 128, 0],\n",
        "    [0, 0, 128],\n",
        "    [128, 0, 128],\n",
        "    [0, 128, 128],\n",
        "    [128, 128, 128],\n",
        "    [64, 0, 0],\n",
        "    [192, 0, 0],\n",
        "    [64, 128, 0],\n",
        "    [192, 128, 0],\n",
        "    [64, 0, 128],\n",
        "    [192, 0, 128],\n",
        "    [64, 128, 128],\n",
        "    [192, 128, 128],\n",
        "    [0, 64, 0],\n",
        "    [128, 64, 0],\n",
        "    [0, 192, 0],\n",
        "    [128, 192, 0],\n",
        "    [0, 64, 128],\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQTPgDWYgHJx"
      },
      "outputs": [],
      "source": [
        "train_transform = A.Compose([\n",
        "    A.Resize(width=256, height=256),\n",
        "    A.ShiftScaleRotate(),\n",
        "    A.HorizontalFlip(),\n",
        "    A.RandomBrightnessContrast(),\n",
        "    A.Blur(),\n",
        "    A.Sharpen(),\n",
        "    A.RGBShift(),\n",
        "    A.Cutout(num_holes=5, max_h_size=25, max_w_size=25, fill_value=0),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "\n",
        "])\n",
        "\n",
        "test_trainsform = A.Compose([\n",
        "    A.Resize(width=256, height=256),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "    ToTensorV2(),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYgHFUqzqvWQ"
      },
      "outputs": [],
      "source": [
        "class My_Dataset(VOCSegmentation):\n",
        "    def __init__(self, root=\"~/data/pascal_voc\", image_set=\"train\", download=True, transform=None):\n",
        "        super().__init__(root=root, image_set=image_set, download=download, transform=transform)\n",
        "\n",
        "\n",
        "    def _convert_to_segmentation_mask(mask):\n",
        "\n",
        "        height, width = mask.shape[:2]\n",
        "        segmentation_mask = np.zeros((height, width, len(VOC_COLORMAP)), dtype=np.float32)\n",
        "        for label_index, label in enumerate(VOC_COLORMAP):\n",
        "            segmentation_mask[:, :, label_index] = np.all(mask == label, axis=-1).astype(float)\n",
        "        return segmentation_mask\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(self.images[index])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.masks[index])\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "        mask = self._convert_to_segmentation_mask(mask)\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        return image, mask.argmax(dim=2).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0ZpZ1lTrABE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX038Aa_rU8z"
      },
      "outputs": [],
      "source": [
        "train_dataset = My_Dataset(image_set=\"train\", download=True)\n",
        "test_dataset =  My_Dataset(image_set=\"val\", download=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuqto_I0gHJ1"
      },
      "outputs": [],
      "source": [
        "\n",
        "image, mask = train_dataset.__getitem__(10)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow((image).permute(1, 2, 0))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask)\n",
        "plt.show()\n",
        "print(mask.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCLejh50gHJ2"
      },
      "outputs": [],
      "source": [
        "#metrics\n",
        "def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n",
        "    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n",
        "    assert (output.dim() in [1, 2, 3])\n",
        "    assert output.shape == target.shape\n",
        "    output = output.view(-1)\n",
        "    target = target.view(-1)\n",
        "    output[target == ignore_index] = ignore_index\n",
        "    intersection = output[output == target]\n",
        "    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n",
        "    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n",
        "    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n",
        "    area_union = area_output + area_target - area_intersection\n",
        "    return area_intersection, area_union, area_target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42jybNBXraHO"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjMNUy8hroWj"
      },
      "outputs": [],
      "source": [
        "#device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#load data\n",
        "batch_size = 8\n",
        "#batch_size = 4\n",
        "n_workers = os.cpu_count()\n",
        "print(\"num_workers =\", n_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDjaUWSfgHJ5"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=n_workers)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=n_workers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BKHiKa1gHJ6"
      },
      "outputs": [],
      "source": [
        "# Define your Panoptic Segmentation model with additional layers\n",
        "class PanopticSegmentationModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PanopticSegmentationModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "# Semantic Segmentation Branch\n",
        "        self.conv1_sem = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1_sem = nn.BatchNorm2d(32)\n",
        "        self.relu1_sem = nn.ReLU()\n",
        "        self.conv2_sem = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2_sem = nn.BatchNorm2d(64)\n",
        "        self.relu2_sem = nn.ReLU()\n",
        "        self.conv3_sem = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3_sem = nn.BatchNorm2d(128)\n",
        "        self.relu3_sem = nn.ReLU()\n",
        "        self.conv4_sem = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.bn4_sem = nn.BatchNorm2d(256)\n",
        "        self.relu4_sem = nn.ReLU()\n",
        "        self.conv5_sem = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn5_sem = nn.BatchNorm2d(512)\n",
        "        self.relu5_sem = nn.ReLU()\n",
        "        self.conv_out_sem = nn.Conv2d(in_channels=512, out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "# Instance Segmentation Branch\n",
        "        self.conv1_ins = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1_ins = nn.BatchNorm2d(32)\n",
        "        self.relu1_ins = nn.ReLU()\n",
        "        self.conv2_ins = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2_ins = nn.BatchNorm2d(64)\n",
        "        self.relu2_ins = nn.ReLU()\n",
        "        self.conv3_ins = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3_ins = nn.BatchNorm2d(128)\n",
        "        self.relu3_ins = nn.ReLU()\n",
        "        self.conv4_ins = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.bn4_ins = nn.BatchNorm2d(256)\n",
        "        self.relu4_ins = nn.ReLU()\n",
        "        self.conv5_ins = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn5_ins = nn.BatchNorm2d(512)\n",
        "        self.relu5_ins = nn.ReLU()\n",
        "        self.conv_out_ins = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        " # Semantic Segmentation Branch\n",
        "        x_sem = self.conv1_sem(x)\n",
        "        x_sem = self.bn1_sem(x_sem)\n",
        "        x_sem = self.relu1_sem(x_sem)\n",
        "        x_sem = self.conv2_sem(x_sem)\n",
        "        x_sem = self.bn2_sem(x_sem)\n",
        "        x_sem = self.relu2_sem(x_sem)\n",
        "        x_sem = self.conv3_sem(x_sem)\n",
        "        x_sem = self.bn3_sem(x_sem)\n",
        "        x_sem = self.relu3_sem(x_sem)\n",
        "        x_sem = self.conv4_sem(x_sem)\n",
        "        x_sem = self.bn4_sem(x_sem)\n",
        "        x_sem = self.relu4_sem(x_sem)\n",
        "        x_sem = self.conv5_sem(x_sem)\n",
        "        x_sem = self.bn5_sem(x_sem)\n",
        "        x_sem = self.relu5_sem(x_sem)\n",
        "        x_sem = self.conv_out_sem(x_sem)  # Output semantic mask\n",
        "\n",
        " # Instance Segmentation Branch\n",
        "        x_ins = self.conv1_ins(x)\n",
        "        x_ins = self.bn1_ins(x_ins)\n",
        "        x_ins = self.relu1_ins(x_ins)\n",
        "        x_ins = self.conv2_ins(x_ins)\n",
        "        x_ins = self.bn2_ins(x_ins)\n",
        "        x_ins = self.relu2_ins(x_ins)\n",
        "        x_ins = self.conv3_ins(x_ins)\n",
        "        x_ins = self.bn3_ins(x_ins)\n",
        "        x_ins = self.relu3_ins(x_ins)\n",
        "        x_ins = self.conv4_ins(x_ins)\n",
        "        x_ins = self.bn4_ins(x_ins)\n",
        "        x_ins = self.relu4_ins(x_ins)\n",
        "        x_ins = self.conv5_ins(x_ins)\n",
        "        x_ins = self.bn5_ins(x_ins)\n",
        "        x_ins = self.relu5_ins(x_ins)\n",
        "        x_ins = self.conv_out_ins(x_ins)  # Output instance mask\n",
        "\n",
        " # Combine both branches for panoptic mask\n",
        "\n",
        "        panoptic_mask = torch.cat([x_sem, x_ins], dim=1)\n",
        "\n",
        "        return panoptic_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leteiB_RgHJ7"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_classes = 91 # Number of semantic classes\n",
        "model = PanopticSegmentationModel(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jVL3UfbgHJ7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#loss\n",
        "\n",
        "criterion = model.losses.DiceLoss(mode=\"multiclass\", classes=91) #diceloss = 1-dicescore\n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,betas={0.999,0.987})\n",
        "n_eps = 10000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCcdCW-bgHJ8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#meter\n",
        "train_loss_meter = AverageMeter()\n",
        "intersection_meter = AverageMeter()\n",
        "union_meter = AverageMeter()\n",
        "target_meter = AverageMeter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxihB61rrtZ7"
      },
      "outputs": [],
      "source": [
        "# Trainning LOOP\n",
        "\n",
        "\n",
        "for ep in range(1, 1+n_eps):\n",
        "    train_loss_meter.reset()\n",
        "    intersection_meter.reset()\n",
        "    union_meter.reset()\n",
        "    target_meter.reset()\n",
        "    model.train()\n",
        "\n",
        "    for batch_id, (x, y) in enumerate(tqdm(trainloader), start=1):\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        y_hat = model(x) #(B, C, H, W)\n",
        "        loss = criterion(y_hat, y) #(B, C, H, W) >< (B, H, W)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #save metrics\n",
        "        with torch.no_grad():\n",
        "            train_loss_meter.update(loss.item())\n",
        "            y_hat_mask = y_hat.argmax(dim=1).squeeze(1) # (B, C, H, W) -> (B, 1, H, W) -> (B, H, W)\n",
        "            intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 21)\n",
        "            intersection_meter.update(intersection)\n",
        "            union_meter.update(union)\n",
        "            target_meter.update(target)\n",
        "\n",
        "    #compute iou, dice\n",
        "    with torch.no_grad():\n",
        "        iou_class = intersection_meter.sum / (union_meter.sum + 1e-10) #vector 21D\n",
        "        dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 21D\n",
        "\n",
        "        mIoU = torch.mean(iou_class) #mean vector 21D\n",
        "        mDice = torch.mean(dice_class) #mean vector 21D\n",
        "\n",
        "    print(\"EP {}, train loss = {} IoU = {}, dice = {}\".format(ep, train_loss_meter.avg, mIoU, mDice))\n",
        "\n",
        "    if ep >= 2000:\n",
        "        torch.save(model.state_dict(), \"modelDeepLab_ep_{}.pth\".format(ep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILQIpi79r2BO"
      },
      "outputs": [],
      "source": [
        "# Testing LOOP\n",
        "\n",
        "model.eval()\n",
        "test_intersection_meter = AverageMeter()\n",
        "test_union_meter = AverageMeter()\n",
        "test_target_meter = AverageMeter()\n",
        "with torch.no_grad():\n",
        "    for batch_id, (x, y) in enumerate(tqdm(testloader), start=1):\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        y_hat = model(x)\n",
        "        y_hat = y_hat.squeeze(1)\n",
        "        y_hat_mask = y_hat.argmax(dim=1)\n",
        "\n",
        "        intersection, union, target = intersectionAndUnionGPU(y_hat_mask, y, 21)\n",
        "        test_intersection_meter.update(intersection)\n",
        "        test_union_meter.update(union)\n",
        "        test_target_meter.update(target)\n",
        "\n",
        "    iou_class = test_intersection_meter.sum / (test_union_meter.sum + 1e-10)\n",
        "    dice_class = 2*test_intersection_meter.sum / (test_intersection_meter.sum + test_union_meter.sum + 1e-10)\n",
        "\n",
        "    mIoU = torch.mean(iou_class)\n",
        "    mDice = torch.mean(dice_class)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5gA2fTIgHJ9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'panoptic_segmentation_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gJ4dxxEgHJ-"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "\n",
        "model.eval()\n",
        "test_intersection_meter = AverageMeter()\n",
        "test_union_meter = AverageMeter()\n",
        "test_target_meter = AverageMeter()\n",
        "with torch.no_grad():\n",
        "    for batch_id, (x, y) in enumerate(tqdm(testloader), start=1):\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        y_hat = model(x)\n",
        "        y_hat = y_hat.squeeze(1)\n",
        "        y_hat_mask = y_hat.argmax(dim=1)\n",
        "\n",
        "        intersection, union, target = intersectionAndUnionGPU(y_hat_mask, y, 21)\n",
        "        test_intersection_meter.update(intersection)\n",
        "        test_union_meter.update(union)\n",
        "        test_target_meter.update(target)\n",
        "\n",
        "    iou_class = test_intersection_meter.sum / (test_union_meter.sum + 1e-10)\n",
        "    dice_class = 2*test_intersection_meter.sum / (test_intersection_meter.sum + test_union_meter.sum + 1e-10)\n",
        "\n",
        "    mIoU = torch.mean(iou_class)\n",
        "    mDice = torch.mean(dice_class)\n",
        "\n",
        "print(\"TEST: IoU = {}, dice = {}\".format(mIoU, mDice))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg2pl-eIr6X0"
      },
      "outputs": [],
      "source": [
        "#prediction\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "id = random.randint(0, test_dataset.__len__())\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    x, y = test_dataset.__getitem__(id)\n",
        "    y_predict = model(x.unsqueeze(0).to(device)).argmax(dim=1).squeeze()\n",
        "    intersection, union, target = intersectionAndUnionGPU(y_predict.float(), y.to(device).float(), 21)\n",
        "    iou_class = intersection / (union + 1e-10)\n",
        "    dice_class = 2*intersection / (intersection + union + 1e-10)\n",
        "    mIoU = torch.mean(iou_class)\n",
        "    mDice = torch.mean(dice_class)\n",
        "    print(\"IoU = {}\\n dice = {}\".format(iou_class, dice_class))\n",
        "    y_predict = y_predict.cpu().numpy()\n",
        "#     print(np.unique(y_predict))\n",
        "    for i in np.unique(y_predict):\n",
        "        print(VOC_CLASSES[i])\n",
        "    color_mask_predict = np.zeros((*y_predict.shape, 3))\n",
        "    for i, color in enumerate(VOC_COLORMAP):\n",
        "        color_mask_predict[y_predict==i] = np.array(color)\n",
        "    color_mask = np.zeros((*y_predict.shape, 3))\n",
        "    for i, color in enumerate(VOC_COLORMAP):\n",
        "        color_mask[y==i] = np.array(color)\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(unorm(x).permute(1, 2, 0))\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(color_mask)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(color_mask_predict)\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}